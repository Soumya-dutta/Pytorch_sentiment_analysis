{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDZRBth-Ipyj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efde24a4-d2b4-4de5-8697-6867d280d6f4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount = True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8uCVqbOIz_N"
      },
      "source": [
        "dataset_path = '/content/gdrive/My Drive/Projects/Pytorch/Sentiment_analysis/'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5asiRg9HTiGA"
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "\n",
        "SEED = 1234\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchtext\n",
        "\n",
        "import nltk\n",
        "\n",
        "import random\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#import pyprind\n",
        "%matplotlib inline "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yA5DlkvXT0KM"
      },
      "source": [
        "import spacy\n",
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbaYUGENT29E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fa62ea9-99bd-4918-f0e7-0e2967b4c467"
      },
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "print(\"Cuda Status on system is {}\".format(is_cuda))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda Status on system is True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1lSLHHn4p72"
      },
      "source": [
        "Different filter sizes that we want in our CNN model. Filter size of 3 means that filter will focus on 3 consecutive words in the sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRXr0WEn1_bM"
      },
      "source": [
        "FILTER_SIZES = [3,4,5]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFibA6oB48gp"
      },
      "source": [
        "Tokenizing each sentence and adding PAD tokens if the length is less than the length of the filter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUwwB0yOT5Yu"
      },
      "source": [
        "def tokenizer(text):\n",
        "    token = [t.text for t in spacy_en.tokenizer(text)]\n",
        "    if len(token) < FILTER_SIZES[-1]:\n",
        "        for i in range(0, FILTER_SIZES[-1] - len(token)):\n",
        "            token.append('<PAD>')\n",
        "    return token"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WGidfSGT9Bu"
      },
      "source": [
        "TEXT = data.Field(tokenize = tokenizer, batch_first = True)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3oiPxp6hIMT"
      },
      "source": [
        "LABEL = data.LabelField(dtype = torch.long)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5qlXIteVUvL"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvScAnb5VZQi"
      },
      "source": [
        "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
        "    path=dataset_path, train=\"sst_train.csv\", \n",
        "    validation=\"sst_dev.csv\", test=\"sst_test.csv\",format=\"csv\", skip_header=True, \n",
        "    fields=[('text', TEXT), ('truth', LABEL)]\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAAgHVcaV9X1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfa15745-e35c-4a4f-8987-bedb403658dc"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of valid examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 8544\n",
            "Number of valid examples: 1101\n",
            "Number of testing examples: 2210\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tViEfNb1WF8M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6be08b71-c870-4214-93ef-28727b01aae2"
      },
      "source": [
        "TEXT.build_vocab(train_data, vectors=torchtext.vocab.Vectors(dataset_path+\"glove.840B.300d.txt\"), \n",
        "                 max_size=25000,unk_init = torch.Tensor.normal_)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 2195820/2196017 [05:50<00:00, 6564.84it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljOZZYslhLU4"
      },
      "source": [
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L1bscbSWTH0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "341c8c1d-cbdd-4831-9392-9b35d0a0a0ee"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), sort_key=lambda x: len(x.text),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    sort_within_batch=True,\n",
        "    device=device)\n",
        "LABEL.vocab.freqs"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'1': 1092, '2': 2218, '3': 1624, '4': 2322, '5': 1288})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJugSjG769pD"
      },
      "source": [
        "A CNN model is defined\n",
        "\n",
        "1.   CNN filters are added on the text to extract features\n",
        "2.   All of them are combined as passed through a FC layer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzwzUC0sYfrq"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
        "                 dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "                \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "        \n",
        "        self.convs = nn.ModuleList([\n",
        "                                    nn.Conv2d(in_channels = 1, \n",
        "                                              out_channels = n_filters, \n",
        "                                              kernel_size = (fs, embedding_dim)) \n",
        "                                    for fs in filter_sizes\n",
        "                                    ])\n",
        "        \n",
        "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "                \n",
        "        #text = [batch size, sent len]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "                \n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "        \n",
        "        embedded = embedded.unsqueeze(1)\n",
        "        \n",
        "        #embedded = [batch size, 1, sent len, emb dim]\n",
        "        \n",
        "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
        "            \n",
        "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
        "                \n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "        \n",
        "        #pooled_n = [batch size, n_filters]\n",
        "        \n",
        "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
        "\n",
        "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
        "            \n",
        "        return self.fc(cat)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CymWrQo47TIe"
      },
      "source": [
        "The best set of hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDvFOEfYcD_b"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 300\n",
        "N_FILTERS = 100\n",
        "OUTPUT_DIM = 5\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ov0Tq_hckoS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "61b6e496-0c77-45e3-8681-1ebafdd98cab"
      },
      "source": [
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 5,511,605 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGkhGWj4cnqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71393ddc-d189-4b34-e6d6-8ee960f19ae6"
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0120,  0.2075, -0.1258,  ...,  0.1387, -0.3605, -0.0350],\n",
              "        ...,\n",
              "        [ 0.0495, -0.2737, -0.2819,  ..., -0.2686,  0.5445,  0.1999],\n",
              "        [ 0.8430, -0.0559, -0.0837,  ...,  0.9208, -0.2708, -0.4322],\n",
              "        [ 0.4218,  0.2891,  0.6224,  ..., -0.0994, -0.3216, -0.2066]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8eO_kIAcrNp"
      },
      "source": [
        "\n",
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LP7TcVaGcuAp"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkX1C8k9cwp9"
      },
      "source": [
        "def binary_accuracy(preds1, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    preds, ind= torch.max(F.softmax(preds1),1)\n",
        "    correct = (ind == y).float()\n",
        "    acc = correct.sum()/float(len(correct))\n",
        "    return acc"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycstY7MLc-d-"
      },
      "source": [
        "\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(batch.text).squeeze(1)\n",
        "        loss = criterion(predictions, batch.truth)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.truth)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe1cW1XgdBXb"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.text).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.truth)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.truth)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kYr0rzedDQD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "2e449558-69c7-4c97-97c7-44eb48e3f47d"
      },
      "source": [
        "N_EPOCHS = 20\n",
        "best_valid_loss = float('inf')\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), dataset_path+'model-cnn.pt')\n",
        "    #test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "    \n",
        "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| Epoch: 01 | Train Loss: 1.549 | Train Acc: 30.47% | Val. Loss: 1.500 | Val. Acc: 35.74\n",
            "| Epoch: 02 | Train Loss: 1.447 | Train Acc: 38.81% | Val. Loss: 1.422 | Val. Acc: 39.27\n",
            "| Epoch: 03 | Train Loss: 1.355 | Train Acc: 43.36% | Val. Loss: 1.362 | Val. Acc: 40.21\n",
            "| Epoch: 04 | Train Loss: 1.276 | Train Acc: 47.38% | Val. Loss: 1.332 | Val. Acc: 41.10\n",
            "| Epoch: 05 | Train Loss: 1.213 | Train Acc: 50.83% | Val. Loss: 1.305 | Val. Acc: 42.17\n",
            "| Epoch: 06 | Train Loss: 1.156 | Train Acc: 54.12% | Val. Loss: 1.290 | Val. Acc: 42.62\n",
            "| Epoch: 07 | Train Loss: 1.101 | Train Acc: 56.64% | Val. Loss: 1.274 | Val. Acc: 44.22\n",
            "| Epoch: 08 | Train Loss: 1.054 | Train Acc: 60.05% | Val. Loss: 1.272 | Val. Acc: 43.56\n",
            "| Epoch: 09 | Train Loss: 0.995 | Train Acc: 63.76% | Val. Loss: 1.266 | Val. Acc: 44.18\n",
            "| Epoch: 10 | Train Loss: 0.948 | Train Acc: 66.35% | Val. Loss: 1.261 | Val. Acc: 45.16\n",
            "| Epoch: 11 | Train Loss: 0.896 | Train Acc: 68.63% | Val. Loss: 1.259 | Val. Acc: 44.94\n",
            "| Epoch: 12 | Train Loss: 0.835 | Train Acc: 71.97% | Val. Loss: 1.258 | Val. Acc: 44.00\n",
            "| Epoch: 13 | Train Loss: 0.794 | Train Acc: 73.92% | Val. Loss: 1.272 | Val. Acc: 45.21\n",
            "| Epoch: 14 | Train Loss: 0.734 | Train Acc: 77.28% | Val. Loss: 1.272 | Val. Acc: 45.12\n",
            "| Epoch: 15 | Train Loss: 0.684 | Train Acc: 79.83% | Val. Loss: 1.279 | Val. Acc: 45.30\n",
            "| Epoch: 16 | Train Loss: 0.631 | Train Acc: 82.40% | Val. Loss: 1.286 | Val. Acc: 44.45\n",
            "| Epoch: 17 | Train Loss: 0.588 | Train Acc: 83.93% | Val. Loss: 1.297 | Val. Acc: 45.34\n",
            "| Epoch: 18 | Train Loss: 0.543 | Train Acc: 85.70% | Val. Loss: 1.310 | Val. Acc: 44.58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqCwlf--7XMy"
      },
      "source": [
        "Test accuracy was **45.80%**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJ_yTlNJdJ5y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb15971f-aab9-4325-fd8f-c7ffb26723d4"
      },
      "source": [
        "model.load_state_dict(torch.load(dataset_path+'model-cnn.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 1.200 | Test Acc: 45.80%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Idk6lA826lAt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}